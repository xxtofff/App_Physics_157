{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset - Classification\n",
    "### Genesis Adam D. Mendoza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Datasets\\\\Titanic Dataset\\\\'\n",
    "titanic = pd.read_csv(file_path + 'train.csv', index_col = 'PassengerId')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Honorific</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CabinName</th>\n",
       "      <th>CabinNumber</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Braund</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>C</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>C</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Allen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "PassengerId                                                                   \n",
       "1                   0       3    male  22.0      1      0         A/5 21171   \n",
       "2                   1       1  female  38.0      1      0          PC 17599   \n",
       "3                   1       3  female  26.0      0      0  STON/O2. 3101282   \n",
       "4                   1       1  female  35.0      1      0            113803   \n",
       "5                   0       3    male  35.0      0      0            373450   \n",
       "\n",
       "                Fare Embarked Honorific    Surname CabinName CabinNumber  \n",
       "PassengerId                                                               \n",
       "1             7.2500        S        Mr     Braund       NaN         NaN  \n",
       "2            71.2833        C       Mrs    Cumings         C          85  \n",
       "3             7.9250        S      Miss  Heikkinen       NaN         NaN  \n",
       "4            53.1000        S       Mrs   Futrelle         C         123  \n",
       "5             8.0500        S        Mr      Allen       NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['Honorific'] = titanic['Name'].str.extract('([A-Za-z]+)\\.')\n",
    "titanic['Surname'] = titanic['Name'].str.extract('([A-Za-z]+)\\,')\n",
    "titanic['CabinName'] = titanic.Cabin.str.extract(r'([A-Z])')\n",
    "titanic['CabinNumber'] = titanic.Cabin.str.extract(r'(\\d+)', expand=False)\n",
    "titanic_dropped = titanic.drop(['Name', 'Cabin'], axis = 1)\n",
    "titanic_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['Survived']\n",
    "feature_cols = [col for col in titanic_dropped.columns if col not in target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in feature_cols if titanic_dropped[col].dtype in ['int64', 'float64']]\n",
    "cat_cols = [col for col in feature_cols if titanic_dropped[col].dtype in ['object']]                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feats = titanic_dropped[feature_cols]\n",
    "y_targ = titanic_dropped[target_cols]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feats, y_targ, train_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = SimpleImputer(strategy = 'mean')\n",
    "categorical_transformer = Pipeline(steps = [('imputer', SimpleImputer(strategy = 'most_frequent')),('onehot', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, num_cols), ('cat', categorical_transformer, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters are (max_leaf_nodes, n_estimators, max_depth) = (160, 61, 36) with an accuracy of 84.08%\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "for node_val in range(10,500,50):\n",
    "    for estim in range(1, 200, 20):\n",
    "        for depth in range(1, 100, 1):\n",
    "            model = RandomForestClassifier(n_estimators = estim, max_leaf_nodes = node_val, max_depth = depth, random_state = 0)\n",
    "            pipeline = Pipeline(steps = [('preprocess', preprocessor),('model', model)])\n",
    "            pipeline.fit(x_train, y_train.values.ravel())\n",
    "            predicted_vals = pipeline.predict(x_test)\n",
    "            y_pred = pd.DataFrame(predicted_vals, index = y_test.index, columns = {'SurvivedPred'})\n",
    "            correct = y_pred.SurvivedPred[y_pred.SurvivedPred == y_test.Survived].count()\n",
    "            total = y_test.Survived.count()\n",
    "            params[(node_val, estim, depth)] = 100*correct/total\n",
    "optimal_params = max(params, key = params.get)\n",
    "opt_nodes, opt_estim, opt_depth = optimal_params\n",
    "print('The optimal parameters are (max_leaf_nodes, n_estimators, max_depth) = {} with an accuracy of {:.2f}%'.format(optimal_params, params[optimal_params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Datasets\\\\Titanic Dataset\\\\'\n",
    "titanic_test = pd.read_csv(file_path + 'test.csv', index_col = 'PassengerId')\n",
    "titanic_test['Honorific'] = titanic_test['Name'].str.extract('([A-Za-z]+)\\.')\n",
    "titanic_test['Surname'] = titanic_test['Name'].str.extract('([A-Za-z]+)\\,')\n",
    "titanic_test['CabinName'] = titanic_test.Cabin.str.extract(r'([A-Z])')\n",
    "titanic_test['CabinNumber'] = titanic_test.Cabin.str.extract(r'(\\d+)', expand=False)\n",
    "titanic_test_dropped = titanic_test.drop(['Name', 'Cabin'], axis = 1)\n",
    "titanic_test_dropped.head()\n",
    "\n",
    "good_cols = [col for col in feature_cols if col in titanic_test.columns]\n",
    "x_deploy = titanic_test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = opt_estim, max_leaf_nodes = opt_nodes, max_depth = opt_depth, random_state = 0)\n",
    "pipeline = Pipeline(steps = [('preprocess', preprocessor),('model', model)])\n",
    "pipeline.fit(x_feats, y_targ.values.ravel())\n",
    "final_pred = pipeline.predict(x_deploy)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': titanic_test.index, 'Survived': final_pred})\n",
    "output.to_csv('titanic_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle's accuracy score is given below:\n",
    "\n",
    "<div>\n",
    "<img src=\"Images/Kaggle_Titanic.jpg\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The best score given the optimum parameters is 84.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "pipeline = Pipeline(steps=[('preprocess', preprocessor), ('model', model)])\n",
    "\n",
    "max_leaf_nodes = [node_val for node_val in range(1, 500, 1)]\n",
    "max_depth = [depth for depth in range(1, 100, 1)]\n",
    "\n",
    "random_grid = {'model__max_leaf_nodes': max_leaf_nodes, 'model__max_depth': max_depth}\n",
    "n_estimators = [estim for estim in range(1, 200, 1)]\n",
    "\n",
    "model_random = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions={**random_grid, 'model__n_estimators': n_estimators},\n",
    "    n_iter=100, cv=5, verbose=3, random_state=0, n_jobs=-1\n",
    ")\n",
    "\n",
    "model_random.fit(x_feats, y_targ.values.ravel())\n",
    "print('The best score given the optimum parameters is {:.2f}%'.format(100*model_random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_estim = model_random.best_params_['model__n_estimators']\n",
    "opt_nodes = model_random.best_params_['model__max_leaf_nodes']\n",
    "opt_depth = model_random.best_params_['model__max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = opt_estim, max_leaf_nodes = opt_nodes, max_depth = opt_depth, random_state = 0)\n",
    "pipeline = Pipeline(steps = [('preprocess', preprocessor),('model', model)])\n",
    "pipeline.fit(x_feats, y_targ.values.ravel())\n",
    "final_pred = pipeline.predict(x_deploy)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': titanic_test.index, 'Survived': final_pred})\n",
    "output.to_csv('titanic_predict_rscv.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
