{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Housing Dataset\n","\n","Suppose we want to buy a house from a neighbourhood, and we have data that contains the general characteristic of the neighborhood, houses, and the population itself. To temper our expectations, we want to predict the median house value."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\PC\\AppData\\Local\\Temp/ipykernel_12736/108761798.py:1: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","      <th>ocean_proximity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-122.23</td>\n","      <td>37.88</td>\n","      <td>41.0</td>\n","      <td>880.0</td>\n","      <td>129.0</td>\n","      <td>322.0</td>\n","      <td>126.0</td>\n","      <td>8.3252</td>\n","      <td>452600.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-122.22</td>\n","      <td>37.86</td>\n","      <td>21.0</td>\n","      <td>7099.0</td>\n","      <td>1106.0</td>\n","      <td>2401.0</td>\n","      <td>1138.0</td>\n","      <td>8.3014</td>\n","      <td>358500.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-122.24</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1467.0</td>\n","      <td>190.0</td>\n","      <td>496.0</td>\n","      <td>177.0</td>\n","      <td>7.2574</td>\n","      <td>352100.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-122.25</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1274.0</td>\n","      <td>235.0</td>\n","      <td>558.0</td>\n","      <td>219.0</td>\n","      <td>5.6431</td>\n","      <td>341300.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-122.25</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1627.0</td>\n","      <td>280.0</td>\n","      <td>565.0</td>\n","      <td>259.0</td>\n","      <td>3.8462</td>\n","      <td>342200.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","0    -122.23     37.88                41.0        880.0           129.0   \n","1    -122.22     37.86                21.0       7099.0          1106.0   \n","2    -122.24     37.85                52.0       1467.0           190.0   \n","3    -122.25     37.85                52.0       1274.0           235.0   \n","4    -122.25     37.85                52.0       1627.0           280.0   \n","\n","   population  households  median_income  median_house_value ocean_proximity  \n","0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n","1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n","2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n","3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n","4       565.0       259.0         3.8462            342200.0        NEAR BAY  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd \n","import numpy as np \n","\n","file_path = '..\\\\datasets\\\\'\n","housing = pd.read_csv(file_path + 'housing.csv')\n","housing.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20640 entries, 0 to 20639\n","Data columns (total 10 columns):\n"," #   Column              Non-Null Count  Dtype  \n","---  ------              --------------  -----  \n"," 0   longitude           20640 non-null  float64\n"," 1   latitude            20640 non-null  float64\n"," 2   housing_median_age  20640 non-null  float64\n"," 3   total_rooms         20640 non-null  float64\n"," 4   total_bedrooms      20433 non-null  float64\n"," 5   population          20640 non-null  float64\n"," 6   households          20640 non-null  float64\n"," 7   median_income       20640 non-null  float64\n"," 8   median_house_value  20640 non-null  float64\n"," 9   ocean_proximity     20640 non-null  object \n","dtypes: float64(9), object(1)\n","memory usage: 1.6+ MB\n"]}],"source":["housing.info()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","      <td>20433.000000</td>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","      <td>20640.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-119.569704</td>\n","      <td>35.631861</td>\n","      <td>28.639486</td>\n","      <td>2635.763081</td>\n","      <td>537.870553</td>\n","      <td>1425.476744</td>\n","      <td>499.539680</td>\n","      <td>3.870671</td>\n","      <td>206855.816909</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.003532</td>\n","      <td>2.135952</td>\n","      <td>12.585558</td>\n","      <td>2181.615252</td>\n","      <td>421.385070</td>\n","      <td>1132.462122</td>\n","      <td>382.329753</td>\n","      <td>1.899822</td>\n","      <td>115395.615874</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-124.350000</td>\n","      <td>32.540000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.499900</td>\n","      <td>14999.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-121.800000</td>\n","      <td>33.930000</td>\n","      <td>18.000000</td>\n","      <td>1447.750000</td>\n","      <td>296.000000</td>\n","      <td>787.000000</td>\n","      <td>280.000000</td>\n","      <td>2.563400</td>\n","      <td>119600.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-118.490000</td>\n","      <td>34.260000</td>\n","      <td>29.000000</td>\n","      <td>2127.000000</td>\n","      <td>435.000000</td>\n","      <td>1166.000000</td>\n","      <td>409.000000</td>\n","      <td>3.534800</td>\n","      <td>179700.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>-118.010000</td>\n","      <td>37.710000</td>\n","      <td>37.000000</td>\n","      <td>3148.000000</td>\n","      <td>647.000000</td>\n","      <td>1725.000000</td>\n","      <td>605.000000</td>\n","      <td>4.743250</td>\n","      <td>264725.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>-114.310000</td>\n","      <td>41.950000</td>\n","      <td>52.000000</td>\n","      <td>39320.000000</td>\n","      <td>6445.000000</td>\n","      <td>35682.000000</td>\n","      <td>6082.000000</td>\n","      <td>15.000100</td>\n","      <td>500001.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          longitude      latitude  housing_median_age   total_rooms  \\\n","count  20640.000000  20640.000000        20640.000000  20640.000000   \n","mean    -119.569704     35.631861           28.639486   2635.763081   \n","std        2.003532      2.135952           12.585558   2181.615252   \n","min     -124.350000     32.540000            1.000000      2.000000   \n","25%     -121.800000     33.930000           18.000000   1447.750000   \n","50%     -118.490000     34.260000           29.000000   2127.000000   \n","75%     -118.010000     37.710000           37.000000   3148.000000   \n","max     -114.310000     41.950000           52.000000  39320.000000   \n","\n","       total_bedrooms    population    households  median_income  \\\n","count    20433.000000  20640.000000  20640.000000   20640.000000   \n","mean       537.870553   1425.476744    499.539680       3.870671   \n","std        421.385070   1132.462122    382.329753       1.899822   \n","min          1.000000      3.000000      1.000000       0.499900   \n","25%        296.000000    787.000000    280.000000       2.563400   \n","50%        435.000000   1166.000000    409.000000       3.534800   \n","75%        647.000000   1725.000000    605.000000       4.743250   \n","max       6445.000000  35682.000000   6082.000000      15.000100   \n","\n","       median_house_value  \n","count        20640.000000  \n","mean        206855.816909  \n","std         115395.615874  \n","min          14999.000000  \n","25%         119600.000000  \n","50%         179700.000000  \n","75%         264725.000000  \n","max         500001.000000  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["housing.describe()"]},{"cell_type":"markdown","metadata":{},"source":["We want to predict the `median_house_value` column. What we want to do is to separate the column we want to predict, or the target column, from the possible determinants that we will use for the prediction, or the feature columns. Then, we split the data into the training set and the test set."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","target_cols = ['median_house_value']\n","feature_cols = [col for col in housing.columns if col not in target_cols]\n","\n","x_full = housing[feature_cols]\n","y = housing[target_cols]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x_full, y, train_size = 0.8, random_state = 0)"]},{"cell_type":"markdown","metadata":{},"source":["It is important to check if there are blank cells and the feature column where it is included so we can deal with it in the future. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['total_bedrooms']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["null_cols = [col for col in x_full.columns if x_full[col].isnull().any()]\n","null_cols"]},{"cell_type":"markdown","metadata":{},"source":["Check the amount of rows where there are no entries."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 207 rows with NaN values\n"]}],"source":["nan_count = x_full[null_cols].isnull().sum().sum()\n","print('There are {} rows with NaN values'.format(nan_count))"]},{"cell_type":"markdown","metadata":{},"source":["We will list the numerical and categorical columns."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The numerical columns are: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n","The categorical columns are: ['ocean_proximity']\n"]}],"source":["num_cols = [col for col in feature_cols if x_full[col].dtype in ['int64', 'float64']]\n","categorical_cols = [col for col in feature_cols if x_full[col].dtype in ['object']]\n","\n","print('The numerical columns are: {}'.format(num_cols))\n","print('The categorical columns are: {}'.format(categorical_cols))"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, the column with a null cell is numerical. We can preprocess the data by filling the null cell with the mean value. It is better than simply putting in 0 total bedrooms for a community."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","\n","num_transformer = SimpleImputer(strategy = 'median')\n","cat_transformer = OneHotEncoder(handle_unknown = 'ignore')\n","preprocess = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat', cat_transformer, categorical_cols)])"]},{"cell_type":"markdown","metadata":{},"source":["Next, we will use a Random Forest Regressor with a max depth of 30."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","import random\n","\n","depth = {}\n","for max_depth_val in random.choices([*range(1, 50, 1)], k = 10):\n","    model = RandomForestRegressor(max_depth = max_depth_val, random_state = 0)\n","    pipeline = Pipeline(steps = [('preprocessor', preprocess), ('model', model)])\n","    pipeline.fit(x_train, y_train.values.ravel())\n","    predicted_val = pipeline.predict(x_test)\n","    error = mean_squared_error(y_test, predicted_val)\n","    depth[max_depth_val] = error\n","optim_depth = min(depth, key = depth.get)\n","error = depth[optim_depth]\n","print('The root-mean-square error for a maximum depth of {} is {}.'.format(max_depth_val, np.sqrt(error)))"]},{"cell_type":"markdown","metadata":{},"source":["For comparison, we can check the actual and predicted values side-by-side."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = RandomForestRegressor(max_depth = optim_depth, random_state = 0)\n","pipeline = Pipeline(steps = [('preprocessor', preprocess), ('model', model)])\n","pipeline.fit(x_train, y_train.values.ravel())\n","predicted_val = pipeline.predict(x_test)\n","predicted_cols = pd.DataFrame(predicted_val, columns = ['predicted'], index = y_test.index)\n","comparison_table = y_test.join(predicted_cols)\n","comparison_table.head()"]},{"cell_type":"markdown","metadata":{},"source":["We can actually search for parameters that will make this error lower. For example, we can make loops that calculate the error for a corresponding parameter and find the parameter value that minimizes this error. If we will do this for all parameters, it may be computationally expensive. I want to try hyperparameter tuning as described in [this article](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74) but as we can see, the calculation for a maximum depth of 30 takes $>10$ secs. This may consume a lot of time so we will stop here for now."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
